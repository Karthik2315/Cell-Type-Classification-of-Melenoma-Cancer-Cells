{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc7d8ca-e767-4f9f-bf72-531fc69e8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import platform\n",
    "import copy\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value,tokenize_batch\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "from tqdm import tqdm\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c57226-2ec4-47a9-94c2-8bf610017b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c9ba57-68ee-4075-b8dc-f843580f6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=0,\n",
    "    do_train=True,\n",
    "    load_model= \"best_model.pt\",\n",
    "    mask_ratio=0.15,\n",
    "    epochs=20,\n",
    "    n_bins=51,\n",
    "    MVC=False, \n",
    "    ecs_thres=0,  \n",
    "    dab_weight=0,  \n",
    "    lr=1e-4,\n",
    "    batch_size=32, \n",
    "    layer_size=256,  \n",
    "    nlayers=6,\n",
    "    nhead=8,\n",
    "    dropout=0.2,\n",
    "    schedule_ratio=0.9,\n",
    "    save_eval_interval=10,\n",
    "    fast_transformer=False, \n",
    "    pre_norm=True,  \n",
    "    amp=torch.cuda.is_available(),\n",
    "    include_zero_gene=False,\n",
    "    freeze=False,  \n",
    "    DSBN=False,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4220b2b6-204e-4001-a077-551663c0e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "config = DotDict(hyperparameter_defaults)\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b365937d-9358-4702-b41e-56726d9cc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = \"<pad>\"\n",
    "special_tokens = [pad_token, \"<cls>\", \"<eoc>\"]\n",
    "mask_ratio = config.mask_ratio\n",
    "mask_value = \"auto\"\n",
    "include_zero_gene = config.include_zero_gene\n",
    "max_seq_len = 1201\n",
    "n_bins = config.n_bins\n",
    "input_style=\"binned\"\n",
    "output_style = \"binned\"\n",
    "\n",
    "MLM = False\n",
    "CLS = True\n",
    "ADV = False\n",
    "CCE = False\n",
    "MVC = config.MVC\n",
    "ECS = config.ecs_thres > 0\n",
    "DAB = False\n",
    "INPUT_BATCH_LABELS = False\n",
    "input_emb_style = \"continuous\"\n",
    "cell_emb_style = \"cls\"\n",
    "mvc_decoder_style = \"inner product\"\n",
    "ecs_threshold = config.ecs_thres\n",
    "dab_weight = config.dab_weight\n",
    "\n",
    "explicit_zero_prob = MLM and include_zero_gene\n",
    "do_sample_in_train = False and explicit_zero_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0190b871-015d-4bb4-b291-21f4b064c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = config.lr\n",
    "batch_size = config.batch_size\n",
    "eval_batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "schedule_interval = 2\n",
    "\n",
    "fast_transformer = config.fast_transformer\n",
    "fast_transformer_backend = \"flash\"\n",
    "embsize = config.layer_size\n",
    "d_hid = config.layer_size\n",
    "nlayers = config.nlayers\n",
    "nhead = config.nhead\n",
    "dropout = config.dropout\n",
    "\n",
    "log_interval = 100\n",
    "save_eval_interval = config.save_eval_interval\n",
    "do_eval_scib_metrics = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52102c5-6400-4ec6-9190-187099612f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_value = -2\n",
    "pad_value = -1\n",
    "n_input_bins = n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be04c212-2985-4be7-a0e0-f4d8e59adc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAB_separate_optim = True if DAB > 1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124c98b6-1227-4c34-abc0-d87d54d85798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to save/dev_classification_Melonoma-Jul02-16-03\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Melonoma\"\n",
    "save_dir = Path(f\"./save/dev_classification_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")\n",
    "logger = scg.logger\n",
    "scg.utils.add_file_handler(logger, save_dir / \"run.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36fb839-eda8-48d0-ab02-17dc9981b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sc.read_h5ad(\"Main_train.h5ad\")\n",
    "test = sc.read_h5ad(\"Main_test.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb9b07f-fa45-429f-a7c4-ef98c40bc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_gene_by_counts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ae50c-0670-4d55-ac17-d8dc05021d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0053a71e-4c8c-420e-8a06-8c9b9ea48f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.var[\"gene_name\"] = train.var.index.tolist()\n",
    "test.var[\"gene_name\"] = test.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7c0517-3770-4477-8f5b-2fb4d8dc487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_file = \"model/args.json\"\n",
    "model_file = \"model/best_model.pt\"\n",
    "vocab_file = \"model/vocab.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e673d6cc-6185-4664-9de6-63d83b6e68dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('save/dev_classification_Melonoma-Jul02-16-03/vocab.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = GeneVocab.from_file(vocab_file)\n",
    "shutil.copy(vocab_file,save_dir/\"vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb67bcbf-c274-43fc-b654-cabaeb048f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '<cls>', '<eoc>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7731774e-83ea-4364-a86b-c4116e1e04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in special_tokens:\n",
    "    if s not in vocab:\n",
    "        vocab.append_token(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0e0b340-acb1-417a-bf4a-2a2d2f10ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.var[\"id_in_vocab\"] = [1 if gene in vocab else -1 for gene in train.var[\"gene_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8210672-dc99-4bf5-b07d-bd7709b2aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - match 1200/1200 genes in vocabulary of size 60697.\n"
     ]
    }
   ],
   "source": [
    "gene_ids_in_vocab = np.array(train.var[\"id_in_vocab\"])\n",
    "logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b2dd19-c4ff-484c-ba1f-e815c9fe5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:,train.var[\"id_in_vocab\"]>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da3b6368-9a8a-42e1-bc18-d87abcbcb90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 5503 × 1200\n",
       "    obs: 'cells', 'samples', 'cell.types', 'treatment.group', 'Cohort', 'no.of.genes', 'no.of.reads'\n",
       "    var: 'gene_name', 'id_in_vocab'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4918b5d0-fb1c-4c23-9d95-648fe980fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Resume model from best_model.pt, the model args will override the config args.json.\n"
     ]
    }
   ],
   "source": [
    "with open(model_config_file, \"r\") as f:\n",
    "        model_configs = json.load(f)\n",
    "logger.info(\n",
    "        f\"Resume model from {model_file}, the model args will override the \"\n",
    "        f\"config {model_config_file}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63f2b767-1953-4490-9f55-02d1561dd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embsize = model_configs[\"embsize\"]\n",
    "nhead = model_configs[\"nheads\"]\n",
    "d_hid = model_configs[\"d_hid\"]\n",
    "nlayers = 12\n",
    "n_layers_cls = model_configs[\"n_layers_cls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b4b269-8c3d-407b-99d5-ab000699d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = train.X.toarray().flatten()\n",
    "\n",
    "# Remove duplicates and sort\n",
    "unique_vals = np.unique(flat)\n",
    "second_max = unique_vals[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c369d4d3-e2c3-4e27-a132-0dee3af1d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(32.019123, dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e05c0136-5e91-4613-84f8-89991396e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",\n",
    "    filter_gene_by_counts=filter_gene_by_counts,\n",
    "    filter_cell_by_counts=False,\n",
    "    normalize_total=1e4,\n",
    "    result_normed_key=\"X_normed\",\n",
    "    log1p=True,\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,\n",
    "    hvg_flavor=\"seurat_v3\" if True else \"cell_ranger\",\n",
    "    binning=n_bins,\n",
    "    result_binned_key=\"X_binned\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d6e6f2c-c42f-462b-84c6-660c100613e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Log1p transforming ...\n",
      "scGPT - INFO - Binning data ...\n",
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Log1p transforming ...\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor(train, batch_key=None)\n",
    "preprocessor(test, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1c524b6-45e3-486d-83ca-b885ad0e1ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f85baf1-6496-4b25-b7d5-001dc7556a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cells</th>\n",
       "      <th>samples</th>\n",
       "      <th>cell.types</th>\n",
       "      <th>treatment.group</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>no.of.genes</th>\n",
       "      <th>no.of.reads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>cy79_p1_CD45_neg_PDL1_neg_AS_C4_R1_G06_S174_comb</td>\n",
       "      <td>Mel79</td>\n",
       "      <td>Mal</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>4781</td>\n",
       "      <td>43875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>cy121.1_CD45pos_S341</td>\n",
       "      <td>Mel121.1</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>3736</td>\n",
       "      <td>438258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>cy110_CD45pos_S362</td>\n",
       "      <td>Mel110</td>\n",
       "      <td>Macrophage</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6864</td>\n",
       "      <td>1323754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>CY89A_CD45_POS_6_G10_S178_comb</td>\n",
       "      <td>Mel89</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>2857</td>\n",
       "      <td>94005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>Merck_CD45pos_pl4_S83</td>\n",
       "      <td>Mel194</td>\n",
       "      <td>T.CD4</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>4770</td>\n",
       "      <td>1351127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>merck_cd45pos_PL3_S289</td>\n",
       "      <td>Mel194</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>9177</td>\n",
       "      <td>1514743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>cy102_CD45neg_CD90neg_S320</td>\n",
       "      <td>Mel102</td>\n",
       "      <td>Mal</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6954</td>\n",
       "      <td>678925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>cy102_CD45neg_CD90neg_S353</td>\n",
       "      <td>Mel102</td>\n",
       "      <td>Mal</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6871</td>\n",
       "      <td>1153541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>cy106_CD45pos_S250</td>\n",
       "      <td>Mel106</td>\n",
       "      <td>B.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>3784</td>\n",
       "      <td>704292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>CY89NEG_C08_S32_comb</td>\n",
       "      <td>Mel89</td>\n",
       "      <td>Mal</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>4490</td>\n",
       "      <td>180384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5503 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cells   samples  cell.types  \\\n",
       "1001  cy79_p1_CD45_neg_PDL1_neg_AS_C4_R1_G06_S174_comb     Mel79         Mal   \n",
       "6710                              cy121.1_CD45pos_S341  Mel121.1      T.cell   \n",
       "6034                                cy110_CD45pos_S362    Mel110  Macrophage   \n",
       "1447                    CY89A_CD45_POS_6_G10_S178_comb     Mel89      T.cell   \n",
       "4080                             Merck_CD45pos_pl4_S83    Mel194       T.CD4   \n",
       "...                                                ...       ...         ...   \n",
       "3965                            merck_cd45pos_PL3_S289    Mel194      T.cell   \n",
       "5436                        cy102_CD45neg_CD90neg_S320    Mel102         Mal   \n",
       "5471                        cy102_CD45neg_CD90neg_S353    Mel102         Mal   \n",
       "5641                                cy106_CD45pos_S250    Mel106      B.cell   \n",
       "891                               CY89NEG_C08_S32_comb     Mel89         Mal   \n",
       "\n",
       "      treatment.group  Cohort  no.of.genes  no.of.reads  \n",
       "1001  treatment.naive  Tirosh         4781        43875  \n",
       "6710   post.treatment     New         3736       438258  \n",
       "6034   post.treatment     New         6864      1323754  \n",
       "1447  treatment.naive  Tirosh         2857        94005  \n",
       "4080   post.treatment     New         4770      1351127  \n",
       "...               ...     ...          ...          ...  \n",
       "3965   post.treatment     New         9177      1514743  \n",
       "5436   post.treatment     New         6954       678925  \n",
       "5471   post.treatment     New         6871      1153541  \n",
       "5641   post.treatment     New         3784       704292  \n",
       "891   treatment.naive  Tirosh         4490       180384  \n",
       "\n",
       "[5503 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d0fefc0-89f2-457b-ba47-abc8a8e1dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2type_train = dict(enumerate(train.obs[\"cell.types\"].astype(\"category\").cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f17ac910-aaf9-47f4-9666-2fd7500a805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2id_train = {v: k for k, v in id2type_train.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fadcc5c-7ff6-4972-880b-b98494d0b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.obs[\"class id\"] = train.obs[\"cell.types\"].map(type2id_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "658b305a-b24b-4533-84b7-94d022a2417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_key=\"X_binned\"\n",
    "allcounts = (\n",
    "    train.layers[input_layer_key].toarray()\n",
    "    if issparse(train.layers[input_layer_key])\n",
    "    else train.layers[input_layer_key]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ce65887-edd8-4232-aded-d4fdc44adcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cells</th>\n",
       "      <th>samples</th>\n",
       "      <th>cell.types</th>\n",
       "      <th>treatment.group</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>no.of.genes</th>\n",
       "      <th>no.of.reads</th>\n",
       "      <th>class id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>cy79_p1_CD45_neg_PDL1_neg_AS_C4_R1_G06_S174_comb</td>\n",
       "      <td>Mel79</td>\n",
       "      <td>Mal</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>4781</td>\n",
       "      <td>43875</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>cy121.1_CD45pos_S341</td>\n",
       "      <td>Mel121.1</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>3736</td>\n",
       "      <td>438258</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>cy110_CD45pos_S362</td>\n",
       "      <td>Mel110</td>\n",
       "      <td>Macrophage</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6864</td>\n",
       "      <td>1323754</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>CY89A_CD45_POS_6_G10_S178_comb</td>\n",
       "      <td>Mel89</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>2857</td>\n",
       "      <td>94005</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>Merck_CD45pos_pl4_S83</td>\n",
       "      <td>Mel194</td>\n",
       "      <td>T.CD4</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>4770</td>\n",
       "      <td>1351127</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>merck_cd45pos_PL3_S289</td>\n",
       "      <td>Mel194</td>\n",
       "      <td>T.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>9177</td>\n",
       "      <td>1514743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>cy102_CD45neg_CD90neg_S320</td>\n",
       "      <td>Mel102</td>\n",
       "      <td>Mal</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6954</td>\n",
       "      <td>678925</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>cy102_CD45neg_CD90neg_S353</td>\n",
       "      <td>Mel102</td>\n",
       "      <td>Mal</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>6871</td>\n",
       "      <td>1153541</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>cy106_CD45pos_S250</td>\n",
       "      <td>Mel106</td>\n",
       "      <td>B.cell</td>\n",
       "      <td>post.treatment</td>\n",
       "      <td>New</td>\n",
       "      <td>3784</td>\n",
       "      <td>704292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>CY89NEG_C08_S32_comb</td>\n",
       "      <td>Mel89</td>\n",
       "      <td>Mal</td>\n",
       "      <td>treatment.naive</td>\n",
       "      <td>Tirosh</td>\n",
       "      <td>4490</td>\n",
       "      <td>180384</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5503 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cells   samples  cell.types  \\\n",
       "1001  cy79_p1_CD45_neg_PDL1_neg_AS_C4_R1_G06_S174_comb     Mel79         Mal   \n",
       "6710                              cy121.1_CD45pos_S341  Mel121.1      T.cell   \n",
       "6034                                cy110_CD45pos_S362    Mel110  Macrophage   \n",
       "1447                    CY89A_CD45_POS_6_G10_S178_comb     Mel89      T.cell   \n",
       "4080                             Merck_CD45pos_pl4_S83    Mel194       T.CD4   \n",
       "...                                                ...       ...         ...   \n",
       "3965                            merck_cd45pos_PL3_S289    Mel194      T.cell   \n",
       "5436                        cy102_CD45neg_CD90neg_S320    Mel102         Mal   \n",
       "5471                        cy102_CD45neg_CD90neg_S353    Mel102         Mal   \n",
       "5641                                cy106_CD45pos_S250    Mel106      B.cell   \n",
       "891                               CY89NEG_C08_S32_comb     Mel89         Mal   \n",
       "\n",
       "      treatment.group  Cohort  no.of.genes  no.of.reads class id  \n",
       "1001  treatment.naive  Tirosh         4781        43875        4  \n",
       "6710   post.treatment     New         3736       438258        8  \n",
       "6034   post.treatment     New         6864      1323754        3  \n",
       "1447  treatment.naive  Tirosh         2857        94005        8  \n",
       "4080   post.treatment     New         4770      1351127        6  \n",
       "...               ...     ...          ...          ...      ...  \n",
       "3965   post.treatment     New         9177      1514743        8  \n",
       "5436   post.treatment     New         6954       678925        4  \n",
       "5471   post.treatment     New         6871      1153541        4  \n",
       "5641   post.treatment     New         3784       704292        0  \n",
       "891   treatment.naive  Tirosh         4490       180384        4  \n",
       "\n",
       "[5503 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a7961eb-7ec2-498a-b7fb-dd2dc8db23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes_labels = train.obs[\"class id\"].tolist()  # make sure count from 0\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_celltype_labels,\n",
    "    valid_celltype_labels,\n",
    ") = train_test_split(\n",
    "    allcounts, celltypes_labels, test_size=0.1, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f0cdc31-1abf-4d4c-b74e-96083416b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparsity(array):\n",
    "    total_elements = array.size\n",
    "    zero_elements = np.count_nonzero(array == 0)\n",
    "    sparsity = zero_elements / total_elements\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "658a7eb7-26e5-4309-8102-ab0acc5b77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8638755385029617"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sparsity(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af37e1dc-ab61-4674-8415-2df9115dc599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868132183908046"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sparsity(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "796a2f8d-eb7a-41c9-b550-8b0dc009d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4952, 1200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9878c7b-96f1-40ad-b7bb-4c042c4050fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551, 1200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b43e6b6e-16df-473a-b078-17ac8eca7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model is None:\n",
    "    vocab = Vocab(\n",
    "        VocabPybind(genes + special_tokens, None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b297741b-dff9-4a2b-bb7e-63f76cb616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = train.var.gene_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebc23f1a-0071-4df5-9091-13db6ec6a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<pad>\"])\n",
    "gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dd2c0eb-46e2-4f35-9817-87ea207d8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batchy(\n",
    "    data: np.ndarray,\n",
    "    gene_ids: np.ndarray,\n",
    "    return_pt: bool = True,\n",
    "    append_cls: bool = True,\n",
    "    include_zero_gene: bool = False,\n",
    "    cls_id: int = \"<cls>\",\n",
    "    mod_type: np.ndarray = None,\n",
    "    cls_id_mod_type: int = None,\n",
    ") -> List[Tuple[Union[torch.Tensor, np.ndarray]]]:\n",
    "    \"\"\"\n",
    "    Tokenize a batch of data. Returns a list of tuple (gene_id, count).\n",
    "\n",
    "    Args:\n",
    "        data (array-like): A batch of data, with shape (batch_size, n_features).\n",
    "            n_features equals the number of all genes.\n",
    "        gene_ids (array-like): A batch of gene ids, with shape (n_features,).\n",
    "        return_pt (bool): Whether to return torch tensors of gene_ids and counts,\n",
    "            default to True.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuple (gene_id, count) of non zero gene expressions.\n",
    "    \"\"\"\n",
    "    if data.shape[1] != len(gene_ids):\n",
    "        raise ValueError(\n",
    "            f\"Number of features in data ({data.shape[1]}) does not match \"\n",
    "            f\"number of gene_ids ({len(gene_ids)}).\"\n",
    "        )\n",
    "    if mod_type is not None and data.shape[1] != len(mod_type):\n",
    "        raise ValueError(\n",
    "            f\"Number of features in data ({data.shape[1]}) does not match \"\n",
    "            f\"number of mod_type ({len(mod_type)}).\"\n",
    "        )\n",
    "\n",
    "    tokenized_data = []\n",
    "    for i in range(len(data)):\n",
    "        row = data[i]\n",
    "        mod_types = None\n",
    "        if include_zero_gene:\n",
    "            values = row\n",
    "            genes = gene_ids\n",
    "            if mod_type is not None:\n",
    "                mod_types = mod_type\n",
    "        else:\n",
    "            idx = np.nonzero(row)[0]\n",
    "            values = row[idx]\n",
    "            genes = gene_ids[idx]\n",
    "            if mod_type is not None:\n",
    "                mod_types = mod_type[idx]\n",
    "        if append_cls:\n",
    "            genes = np.insert(genes, 0, cls_id)\n",
    "            values = np.insert(values, 0, 0)\n",
    "            if mod_type is not None:\n",
    "                mod_types = np.insert(mod_types, 0, cls_id_mod_type)\n",
    "        if return_pt:\n",
    "            genes = torch.from_numpy(genes).long()\n",
    "            values = torch.from_numpy(values).float()\n",
    "            if mod_type is not None:\n",
    "                mod_types = torch.from_numpy(mod_types).long()\n",
    "        tokenized_data.append((genes, values, mod_types))\n",
    "    return tokenized_data\n",
    "\n",
    "def pad_batchy(\n",
    "    batch: List[Tuple],\n",
    "    max_len: int,\n",
    "    vocab: Vocab,\n",
    "    pad_token: str = \"<pad>\",\n",
    "    pad_value: int = 0,\n",
    "    cls_appended: bool = True,\n",
    "    vocab_mod: Vocab = None,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Pad a batch of data. Returns a list of Dict[gene_id, count].\n",
    "\n",
    "    Args:\n",
    "        batch (list): A list of tuple (gene_id, count).\n",
    "        max_len (int): The maximum length of the batch.\n",
    "        vocab (Vocab): The vocabulary containing the pad token.\n",
    "        pad_token (str): The token to pad with.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, torch.Tensor]: A dictionary of gene_id and count.\n",
    "    \"\"\"\n",
    "    #max_ori_len = max(len(batch[i][0]) for i in range(len(batch)))\n",
    "    #max_len = min(max_ori_len, max_len)\n",
    "\n",
    "    pad_id = vocab[pad_token]\n",
    "    if vocab_mod is not None:\n",
    "        mod_pad_id = vocab_mod[pad_token]\n",
    "    gene_ids_list = []\n",
    "    values_list = []\n",
    "    mod_types_list = []\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        gene_ids, values, mod_types = batch[i]\n",
    "\n",
    "        if len(gene_ids) > max_len:\n",
    "            # sample max_len genes\n",
    "            if not cls_appended:\n",
    "                idx = np.random.choice(len(gene_ids), max_len, replace=False)\n",
    "            else:\n",
    "                idx = np.random.choice(len(gene_ids) - 1, max_len - 1, replace=False)\n",
    "                idx = idx + 1\n",
    "                idx = np.insert(idx, 0, 0)\n",
    "            gene_ids = gene_ids[idx]\n",
    "            values = values[idx]\n",
    "            if mod_types is not None:\n",
    "                mod_types = mod_types[idx]\n",
    "        if len(gene_ids) < max_len:\n",
    "            gene_ids = torch.cat(\n",
    "                [\n",
    "                    gene_ids,\n",
    "                    torch.full(\n",
    "                        (max_len - len(gene_ids),), pad_id, dtype=gene_ids.dtype\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            values = torch.cat(\n",
    "                [\n",
    "                    values,\n",
    "                    torch.full((max_len - len(values),), pad_value, dtype=values.dtype),\n",
    "                ]\n",
    "            )\n",
    "            if mod_types is not None:\n",
    "                mod_types = torch.cat(\n",
    "                    [\n",
    "                        mod_types,\n",
    "                        torch.full(\n",
    "                            (max_len - len(mod_types),),\n",
    "                            mod_pad_id,\n",
    "                            dtype=mod_types.dtype,\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        gene_ids_list.append(gene_ids)\n",
    "        values_list.append(values)\n",
    "        if mod_types is not None:\n",
    "            mod_types_list.append(mod_types)\n",
    "\n",
    "    batch_padded = {\n",
    "        \"genes\": torch.stack(gene_ids_list, dim=0),\n",
    "        \"values\": torch.stack(values_list, dim=0),\n",
    "    }\n",
    "    if mod_types is not None:\n",
    "        batch_padded[\"mod_types\"] = torch.stack(mod_types_list, dim=0)\n",
    "    return batch_padded\n",
    "\n",
    "def tokenize_and_pad_batchy(\n",
    "    data: np.ndarray,\n",
    "    gene_ids: np.ndarray,\n",
    "    max_len: int,\n",
    "    vocab: Vocab,\n",
    "    pad_token: str,\n",
    "    pad_value: int,\n",
    "    append_cls: bool = True,\n",
    "    include_zero_gene: bool = False,\n",
    "    cls_token: str = \"<cls>\",\n",
    "    return_pt: bool = True,\n",
    "    mod_type: np.ndarray = None,\n",
    "    vocab_mod: Vocab = None,\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Tokenize and pad a batch of data. Returns a list of tuple (gene_id, count).\n",
    "    \"\"\"\n",
    "    cls_id = vocab[cls_token]\n",
    "    if mod_type is not None:\n",
    "        cls_id_mod_type = vocab_mod[cls_token]\n",
    "    tokenized_data = tokenize_batchy(\n",
    "        data,\n",
    "        gene_ids,\n",
    "        return_pt=return_pt,\n",
    "        append_cls=append_cls,\n",
    "        include_zero_gene=include_zero_gene,\n",
    "        cls_id=cls_id,\n",
    "        mod_type=mod_type,\n",
    "        cls_id_mod_type=cls_id_mod_type if mod_type is not None else None,\n",
    "    )\n",
    "\n",
    "    batch_padded = pad_batchy(\n",
    "        tokenized_data,\n",
    "        max_len,\n",
    "        vocab,\n",
    "        pad_token,\n",
    "        pad_value,\n",
    "        cls_appended=append_cls,\n",
    "        vocab_mod=vocab_mod,\n",
    "    )\n",
    "    return batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d05a50a-90e8-4e50-9795-a9673d09712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_zero_gene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fabda7-3f10-4a38-a7df-b999b86b8567",
   "metadata": {},
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b0d9a08-ed3d-4192-97c5-da52c6635b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_zero_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f215183b-f258-45bc-8760-3d6cf4e19062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - train set number of samples: 4952, \n",
      "\t feature length: 1201\n",
      "scGPT - INFO - valid set number of samples: 551, \n",
      "\t feature length: 1201\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenize_and_pad_batchy(\n",
    "    train_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=include_zero_gene,\n",
    ")\n",
    "tokenized_valid = tokenize_and_pad_batchy(\n",
    "    valid_data,\n",
    "    gene_ids,\n",
    "    max_len=max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    append_cls=True,\n",
    "    include_zero_gene=include_zero_gene,\n",
    ")\n",
    "logger.info(\n",
    "    f\"train set number of samples: {tokenized_train['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_train['genes'].shape[1]}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"valid set number of samples: {tokenized_valid['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_valid['genes'].shape[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76c63c-0659-49e1-a1a8-3786cd2557db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37eb43b6-813c-4c71-80c0-ada8836612b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data: Dict[str, torch.Tensor]):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"gene_ids\"].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e5019c5-4faf-489c-9f60-a83c20cf905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(\n",
    "    data_pt: Dict[str, torch.Tensor],\n",
    "    batch_size: int,\n",
    "    shuffle: bool = False,\n",
    "    intra_domain_shuffle: bool = False,\n",
    "    drop_last: bool = False,\n",
    "    num_workers: int = None,  # set to None for auto-detection\n",
    ") -> DataLoader:\n",
    "    if num_workers is None:\n",
    "        # Auto-detect optimal number of workers\n",
    "        try:\n",
    "            if platform.system() == \"Windows\":\n",
    "                num_workers = max(1, batch_size // 2)\n",
    "            else:\n",
    "                num_workers = min(os.cpu_count() or 4, batch_size)\n",
    "        except Exception:\n",
    "            num_workers = 0  # fallback if detection fails\n",
    "\n",
    "    dataset = SeqDataset(data_pt)\n",
    "\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),  # Only pin if using GPU\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f123c24-d9ac-46d1-96b9-204790eaee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data() -> Tuple[Dict[str, torch.Tensor]]:\n",
    "    masked_values_train = random_mask_value(\n",
    "        tokenized_train[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "    masked_values_valid = random_mask_value(\n",
    "        tokenized_valid[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    ) \n",
    "    print(\n",
    "        f\"random masking at epoch {epoch:3d}, ratio of masked values in train: \",\n",
    "        f\"{(masked_values_train == mask_value).sum() / (masked_values_train - pad_value).count_nonzero():.4f}\",\n",
    "    ) \n",
    "\n",
    "    input_gene_ids_train, input_gene_ids_valid = (\n",
    "        tokenized_train[\"genes\"],\n",
    "        tokenized_valid[\"genes\"],\n",
    "    )\n",
    "    #input_values_train, input_values_valid = masked_values_train, masked_values_valid\n",
    "    target_values_train, target_values_valid = (\n",
    "        tokenized_train[\"values\"],\n",
    "        tokenized_valid[\"values\"],\n",
    "    )\n",
    "\n",
    "    tensor_celltype_labels_train = torch.from_numpy(train_celltype_labels).long()\n",
    "    tensor_celltype_labels_valid = torch.from_numpy(valid_celltype_labels).long()\n",
    "    input_values_train, input_values_valid = masked_values_train, masked_values_valid\n",
    "\n",
    "    train_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_train,\n",
    "        \"values\": input_values_train,\n",
    "        \"target\":target_values_train,\n",
    "        \"celltype_labels\": tensor_celltype_labels_train,\n",
    "    }\n",
    "    valid_data_pt = {\n",
    "        \"gene_ids\": input_gene_ids_valid,\n",
    "        \"values\": input_values_valid,\n",
    "        \"target\":target_values_valid,\n",
    "        \"celltype_labels\": tensor_celltype_labels_valid,\n",
    "    }\n",
    "\n",
    "    return train_data_pt, valid_data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98fee013-2d16-47a9-884a-d19e63f556cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_types = len(np.unique(celltypes_labels))\n",
    "num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a585445b-ce8d-47f3-963c-13cd224e596c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ntokens = len(vocab)  \n",
    "model = TransformerModel(\n",
    "    ntoken=ntokens,\n",
    "    d_model=embsize,\n",
    "    nhead=nhead,\n",
    "    d_hid=d_hid,\n",
    "    nlayers=12,\n",
    "    nlayers_cls=3,\n",
    "    n_cls=num_types if CLS else 1,\n",
    "    vocab=vocab,\n",
    "    dropout=dropout,\n",
    "    pad_token=pad_token,\n",
    "    pad_value=pad_value,\n",
    "    do_mvc=MVC,\n",
    "    do_dab=DAB,\n",
    "    use_batch_labels=INPUT_BATCH_LABELS,\n",
    "    domain_spec_batchnorm=config.DSBN,\n",
    "    input_emb_style=input_emb_style,\n",
    "    n_input_bins=n_input_bins,\n",
    "    cell_emb_style=cell_emb_style,\n",
    "    mvc_decoder_style=mvc_decoder_style,\n",
    "    ecs_threshold=ecs_threshold,\n",
    "    explicit_zero_prob=explicit_zero_prob,\n",
    "    use_fast_transformer=fast_transformer,\n",
    "    fast_transformer_backend=fast_transformer_backend,\n",
    "    pre_norm=config.pre_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0813ef45-32cf-457f-a00f-3a81acb76993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91391e77-5ed2-4879-b8a8-b340e2987db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_model.pt'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "81c6af8f-e11a-4703-9388-57a68f1a0f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Loading params encoder.embedding.weight with shape torch.Size([60697, 512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params encoder.enc_norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.weight with shape torch.Size([512, 1])\n",
      "scGPT - INFO - Loading params value_encoder.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params value_encoder.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params value_encoder.norm.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.0.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.1.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.2.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.3.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.4.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.5.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.6.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.7.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.8.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.9.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.10.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.self_attn.out_proj.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.linear2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm1.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.weight with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params transformer_encoder.layers.11.norm2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.0.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params decoder.fc.0.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.2.weight with shape torch.Size([512, 512])\n",
      "scGPT - INFO - Loading params decoder.fc.2.bias with shape torch.Size([512])\n",
      "scGPT - INFO - Loading params decoder.fc.4.weight with shape torch.Size([1, 512])\n",
      "scGPT - INFO - Loading params decoder.fc.4.bias with shape torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    logger.info(f\"Loading all model params from {model_file}\")\n",
    "except:\n",
    "        # only load params that are in the model and match the size\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_file)\n",
    "    pretrained_dict = {\n",
    "        k: v\n",
    "        for k, v in pretrained_dict.items()\n",
    "        if k in model_dict and v.shape == model_dict[k].shape\n",
    "    }\n",
    "    for k, v in pretrained_dict.items():\n",
    "        logger.info(f\"Loading params {k} with shape {v.shape}\")\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e5f2c62-fdcd-47d6-ad31-3f352f1851d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embedding.weight\n",
      "encoder.enc_norm.weight\n",
      "encoder.enc_norm.bias\n",
      "value_encoder.linear1.weight\n",
      "value_encoder.linear1.bias\n",
      "value_encoder.linear2.weight\n",
      "value_encoder.linear2.bias\n",
      "value_encoder.norm.weight\n",
      "value_encoder.norm.bias\n",
      "transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.0.linear1.weight\n",
      "transformer_encoder.layers.0.linear1.bias\n",
      "transformer_encoder.layers.0.linear2.weight\n",
      "transformer_encoder.layers.0.linear2.bias\n",
      "transformer_encoder.layers.0.norm1.weight\n",
      "transformer_encoder.layers.0.norm1.bias\n",
      "transformer_encoder.layers.0.norm2.weight\n",
      "transformer_encoder.layers.0.norm2.bias\n",
      "transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.1.linear1.weight\n",
      "transformer_encoder.layers.1.linear1.bias\n",
      "transformer_encoder.layers.1.linear2.weight\n",
      "transformer_encoder.layers.1.linear2.bias\n",
      "transformer_encoder.layers.1.norm1.weight\n",
      "transformer_encoder.layers.1.norm1.bias\n",
      "transformer_encoder.layers.1.norm2.weight\n",
      "transformer_encoder.layers.1.norm2.bias\n",
      "transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.2.linear1.weight\n",
      "transformer_encoder.layers.2.linear1.bias\n",
      "transformer_encoder.layers.2.linear2.weight\n",
      "transformer_encoder.layers.2.linear2.bias\n",
      "transformer_encoder.layers.2.norm1.weight\n",
      "transformer_encoder.layers.2.norm1.bias\n",
      "transformer_encoder.layers.2.norm2.weight\n",
      "transformer_encoder.layers.2.norm2.bias\n",
      "transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.3.linear1.weight\n",
      "transformer_encoder.layers.3.linear1.bias\n",
      "transformer_encoder.layers.3.linear2.weight\n",
      "transformer_encoder.layers.3.linear2.bias\n",
      "transformer_encoder.layers.3.norm1.weight\n",
      "transformer_encoder.layers.3.norm1.bias\n",
      "transformer_encoder.layers.3.norm2.weight\n",
      "transformer_encoder.layers.3.norm2.bias\n",
      "transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.4.linear1.weight\n",
      "transformer_encoder.layers.4.linear1.bias\n",
      "transformer_encoder.layers.4.linear2.weight\n",
      "transformer_encoder.layers.4.linear2.bias\n",
      "transformer_encoder.layers.4.norm1.weight\n",
      "transformer_encoder.layers.4.norm1.bias\n",
      "transformer_encoder.layers.4.norm2.weight\n",
      "transformer_encoder.layers.4.norm2.bias\n",
      "transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.5.linear1.weight\n",
      "transformer_encoder.layers.5.linear1.bias\n",
      "transformer_encoder.layers.5.linear2.weight\n",
      "transformer_encoder.layers.5.linear2.bias\n",
      "transformer_encoder.layers.5.norm1.weight\n",
      "transformer_encoder.layers.5.norm1.bias\n",
      "transformer_encoder.layers.5.norm2.weight\n",
      "transformer_encoder.layers.5.norm2.bias\n",
      "transformer_encoder.layers.6.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.6.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.6.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.6.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.6.linear1.weight\n",
      "transformer_encoder.layers.6.linear1.bias\n",
      "transformer_encoder.layers.6.linear2.weight\n",
      "transformer_encoder.layers.6.linear2.bias\n",
      "transformer_encoder.layers.6.norm1.weight\n",
      "transformer_encoder.layers.6.norm1.bias\n",
      "transformer_encoder.layers.6.norm2.weight\n",
      "transformer_encoder.layers.6.norm2.bias\n",
      "transformer_encoder.layers.7.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.7.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.7.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.7.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.7.linear1.weight\n",
      "transformer_encoder.layers.7.linear1.bias\n",
      "transformer_encoder.layers.7.linear2.weight\n",
      "transformer_encoder.layers.7.linear2.bias\n",
      "transformer_encoder.layers.7.norm1.weight\n",
      "transformer_encoder.layers.7.norm1.bias\n",
      "transformer_encoder.layers.7.norm2.weight\n",
      "transformer_encoder.layers.7.norm2.bias\n",
      "transformer_encoder.layers.8.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.8.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.8.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.8.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.8.linear1.weight\n",
      "transformer_encoder.layers.8.linear1.bias\n",
      "transformer_encoder.layers.8.linear2.weight\n",
      "transformer_encoder.layers.8.linear2.bias\n",
      "transformer_encoder.layers.8.norm1.weight\n",
      "transformer_encoder.layers.8.norm1.bias\n",
      "transformer_encoder.layers.8.norm2.weight\n",
      "transformer_encoder.layers.8.norm2.bias\n",
      "transformer_encoder.layers.9.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.9.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.9.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.9.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.9.linear1.weight\n",
      "transformer_encoder.layers.9.linear1.bias\n",
      "transformer_encoder.layers.9.linear2.weight\n",
      "transformer_encoder.layers.9.linear2.bias\n",
      "transformer_encoder.layers.9.norm1.weight\n",
      "transformer_encoder.layers.9.norm1.bias\n",
      "transformer_encoder.layers.9.norm2.weight\n",
      "transformer_encoder.layers.9.norm2.bias\n",
      "transformer_encoder.layers.10.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.10.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.10.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.10.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.10.linear1.weight\n",
      "transformer_encoder.layers.10.linear1.bias\n",
      "transformer_encoder.layers.10.linear2.weight\n",
      "transformer_encoder.layers.10.linear2.bias\n",
      "transformer_encoder.layers.10.norm1.weight\n",
      "transformer_encoder.layers.10.norm1.bias\n",
      "transformer_encoder.layers.10.norm2.weight\n",
      "transformer_encoder.layers.10.norm2.bias\n",
      "transformer_encoder.layers.11.self_attn.in_proj_weight\n",
      "transformer_encoder.layers.11.self_attn.in_proj_bias\n",
      "transformer_encoder.layers.11.self_attn.out_proj.weight\n",
      "transformer_encoder.layers.11.self_attn.out_proj.bias\n",
      "transformer_encoder.layers.11.linear1.weight\n",
      "transformer_encoder.layers.11.linear1.bias\n",
      "transformer_encoder.layers.11.linear2.weight\n",
      "transformer_encoder.layers.11.linear2.bias\n",
      "transformer_encoder.layers.11.norm1.weight\n",
      "transformer_encoder.layers.11.norm1.bias\n",
      "transformer_encoder.layers.11.norm2.weight\n",
      "transformer_encoder.layers.11.norm2.bias\n",
      "decoder.fc.0.weight\n",
      "decoder.fc.0.bias\n",
      "decoder.fc.2.weight\n",
      "decoder.fc.2.bias\n",
      "decoder.fc.4.weight\n",
      "decoder.fc.4.bias\n",
      "cls_decoder._decoder.0.weight\n",
      "cls_decoder._decoder.0.bias\n",
      "cls_decoder._decoder.2.weight\n",
      "cls_decoder._decoder.2.bias\n",
      "cls_decoder._decoder.3.weight\n",
      "cls_decoder._decoder.3.bias\n",
      "cls_decoder._decoder.5.weight\n",
      "cls_decoder._decoder.5.bias\n",
      "cls_decoder.out_layer.weight\n",
      "cls_decoder.out_layer.bias\n"
     ]
    }
   ],
   "source": [
    "for p,_ in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5740a20-49c5-41b1-9bc6-7aaf38280712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "name: encoder.embedding.weight\n",
      "--------------------\n",
      "name: encoder.enc_norm.weight\n",
      "--------------------\n",
      "name: encoder.enc_norm.bias\n",
      "--------------------\n",
      "name: value_encoder.linear1.weight\n",
      "--------------------\n",
      "name: value_encoder.linear1.bias\n",
      "--------------------\n",
      "name: value_encoder.linear2.weight\n",
      "--------------------\n",
      "name: value_encoder.linear2.bias\n",
      "--------------------\n",
      "name: value_encoder.norm.weight\n",
      "--------------------\n",
      "name: value_encoder.norm.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.0.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.1.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.2.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.3.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.4.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.5.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.6.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.7.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.8.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.9.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.10.norm2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.in_proj_weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.in_proj_bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.out_proj.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.self_attn.out_proj.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.linear2.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm1.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm1.bias\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm2.weight\n",
      "--------------------\n",
      "name: transformer_encoder.layers.11.norm2.bias\n",
      "--------------------\n",
      "name: decoder.fc.0.weight\n",
      "--------------------\n",
      "name: decoder.fc.0.bias\n",
      "--------------------\n",
      "name: decoder.fc.2.weight\n",
      "--------------------\n",
      "name: decoder.fc.2.bias\n",
      "--------------------\n",
      "name: decoder.fc.4.weight\n",
      "--------------------\n",
      "name: decoder.fc.4.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.0.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.0.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.2.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.2.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.3.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.3.bias\n",
      "--------------------\n",
      "name: cls_decoder._decoder.5.weight\n",
      "--------------------\n",
      "name: cls_decoder._decoder.5.bias\n",
      "--------------------\n",
      "name: cls_decoder.out_layer.weight\n",
      "--------------------\n",
      "name: cls_decoder.out_layer.bias\n",
      "scGPT - INFO - Total Pre freeze Params 51336202\n",
      "scGPT - INFO - Total Post freeze Params 51336202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(60697, 512, padding_idx=60694)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): ContinuousValueEncoder(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=9, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "for name, para in model.named_parameters():\n",
    "    print(\"-\"*20)\n",
    "    print(f\"name: {name}\")\n",
    "    if config.freeze and \"encoder\" in name and \"transformer_encoder\" not in name:\n",
    "        print(f\"freezing weights for: {name}\")\n",
    "        para.requires_grad = False\n",
    "post_freeze_param_count = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters() if p.requires_grad).values())\n",
    "logger.info(f\"Total Pre freeze Params {(pre_freeze_param_count )}\")\n",
    "logger.info(f\"Total Post freeze Params {(post_freeze_param_count )}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "797f17de-4532-4136-8c78-848106800499",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, schedule_interval, gamma=config.schedule_ratio\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "406d0c62-6a0f-4ad1-8521-c7eba3306cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def train(model: nn.Module, loader: DataLoader,epoch:int) -> None:\n",
    "    \"\"\"\n",
    "    Train the model for one epoch on CPU.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    (\n",
    "        total_loss\n",
    "    ) = (0.0)\n",
    "    total_error = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(loader)\n",
    "    for batch, batch_data in enumerate(tqdm(loader, desc=f\"Training Epoch {epoch}\", leave=False)):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device,non_blocking=True)\n",
    "        input_values = batch_data[\"values\"].to(device,non_blocking=True)\n",
    "        target_values = batch_data[\"target_values\"].to(device,non_blocking=True)\n",
    "        celltype_labels = batch_data[\"celltype_labels\"].to(device,non_blocking=True)\n",
    "\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "        masked_positions = input_values.eq(mask_value)\n",
    "        output_dict = model(\n",
    "            input_gene_ids,\n",
    "            input_values,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "            CLS=CLS,\n",
    "            CCE=CCE,\n",
    "            MVC=MVC,\n",
    "            ECS=ECS,\n",
    "            do_sample=do_sample_in_train,\n",
    "        )\n",
    "\n",
    "        masked_positions = input_values.eq(mask_value)\n",
    "        loss = 0.0\n",
    "        metrics_to_log = {}\n",
    "\n",
    "                \n",
    "        model.zero_grad()\n",
    "        loss = torch.tensor(loss, device=device, requires_grad=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | \"\n",
    "            )\n",
    "\n",
    "            # Reset\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def chatgpt_train(model: nn.Module, loader: DataLoader,epoch:int) -> None:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    start_time = time.time()\n",
    "    num_batches = len(loader)\n",
    "    \n",
    "    for batch, batch_data in enumerate(tqdm(loader, desc=f\"Training Epoch {epoch}\", leave=False)):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device, non_blocking=True)\n",
    "        input_values = batch_data[\"values\"].to(device, non_blocking=True)\n",
    "        celltype_labels = batch_data[\"celltype_labels\"].to(device, non_blocking=True)\n",
    "        batch_labels = batch_data.get(\"batch_labels\", None)\n",
    "        if batch_labels is not None:\n",
    "            batch_labels = batch_labels.to(device, non_blocking=True)\n",
    "\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=batch_labels if INPUT_BATCH_LABELS or config.DSBN else None,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "                do_sample=do_sample_in_train,\n",
    "            )\n",
    "\n",
    "            loss = None\n",
    "\n",
    "            if MLM:\n",
    "                output = output_dict[\"mlm_output\"]\n",
    "                masked_positions = input_values.eq(mask_value)\n",
    "                for idx, row in enumerate(output):\n",
    "                    masked_position = src_key_padding_mask[idx]\n",
    "                    if masked_position.any():\n",
    "                        predicted_values = row[masked_position]\n",
    "                        gene_tokens = input_gene_ids[idx][masked_position]\n",
    "                        cancer_type, cell_type = id2type_train[celltype_labels[idx].item()].split()\n",
    "                        single_loss = mse_main_loss_vectorized(\n",
    "                            predicted_values,\n",
    "                            cancer_type,\n",
    "                            cell_type,\n",
    "                            gene_tokens,\n",
    "                            device\n",
    "                        )\n",
    "                        if loss is None:\n",
    "                            loss = single_loss\n",
    "                        else:\n",
    "                            loss = loss + single_loss\n",
    "            else:\n",
    "                raise ValueError(\"MLM must be True — no loss defined otherwise.\")\n",
    "            \n",
    "            # === Skip training step if loss is None ===\n",
    "        if loss is not None:\n",
    "                model.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "            \n",
    "                with warnings.catch_warnings(record=True) as w:\n",
    "                    warnings.filterwarnings(\"always\")\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        model.parameters(), 1.0,\n",
    "                        error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "                    )\n",
    "                    if len(w) > 0:\n",
    "                        logger.warning(\n",
    "                            f\"⚠️ Infinite gradient detected (scale={scaler.get_scale()}) — may stabilize after autoscaling.\"\n",
    "                        )\n",
    "            \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            \n",
    "                total_loss += loss.item()\n",
    "\n",
    "            loss = torch.tensor(0.0, device=device)\n",
    "            if MLM:\n",
    "                output = output_dict[\"mlm_output\"]\n",
    "                masked_positions = input_values.eq(mask_value)\n",
    "                for idx, row in enumerate(output):\n",
    "                    masked_position = src_key_padding_mask[idx]\n",
    "                    predicted_values = row[masked_position]\n",
    "                    gene_tokens = input_gene_ids[idx][masked_position]\n",
    "                    cancer_type, cell_type = id2type_train[celltype_labels[idx].item()].split()\n",
    "                    loss += mse_main_loss_vectorized(\n",
    "                                predicted_values,\n",
    "                                cancer_type,\n",
    "                                cell_type,\n",
    "                                gene_tokens,\n",
    "                                device\n",
    "                                )\n",
    "\n",
    "        # Convert float loss to tensor for backward\n",
    "\n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), 1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"⚠️ Infinite gradient detected (scale={scaler.get_scale()}) — may stabilize after autoscaling.\"\n",
    "                )\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | loss {cur_loss:5.4f} |\"\n",
    "            )\n",
    "\n",
    "            # Reset logging stats\n",
    "            total_loss = 0.0\n",
    "            start_time = time.time() '''\n",
    "\n",
    "def chatgpt_train_main(model: nn.Module, loader: DataLoader, epoch: int) -> None:\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_cls = 0.0\n",
    "    total_zero_log_prob = 0.0\n",
    "    start_time = time.time()\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    for batch, batch_data in enumerate(tqdm(loader, desc=f\"Training Epoch {epoch}\", leave=False)):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device, non_blocking=True)\n",
    "        input_values = batch_data[\"values\"].to(device, non_blocking=True)\n",
    "        celltype_labels = batch_data[\"celltype_labels\"].to(device, non_blocking=True)\n",
    "        target_values = batch_data[\"target\"].to(device,non_blocking=True)\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "        loss = 0.0\n",
    "        metrics_to_log = {}\n",
    "        with torch.cuda.amp.autocast(enabled=config.amp):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=None,\n",
    "                CLS=CLS,\n",
    "                CCE=CCE,\n",
    "                MVC=MVC,\n",
    "                ECS=ECS,\n",
    "                do_sample=do_sample_in_train,\n",
    "            )\n",
    "        masked_positions = input_values.eq(mask_value)\n",
    "        if MLM:\n",
    "            loss_mse = criterion(output_dict[\"mlm_output\"], target_values, masked_positions)\n",
    "            loss += loss_mse\n",
    "            metrics_to_log[\"train/mse\"] = loss_mse.item()\n",
    "        if explicit_zero_prob:\n",
    "            loss_zero_log_prob = criterion_neg_log_bernoulli(output_dict[\"mlm_zero_probs\"], target_values, masked_positions)\n",
    "            loss += loss_zero_log_prob\n",
    "            metrics_to_log[\"train/nzlp\"] = loss_zero_log_prob.item()\n",
    "        if CLS:\n",
    "            loss_cls = criterion_cls(output_dict[\"cls_output\"], celltype_labels)\n",
    "            loss += loss_cls\n",
    "            metrics_to_log[\"train/cls\"] = loss_cls.item()\n",
    "            error_rate = 1 - ((output_dict[\"cls_output\"].argmax(1) == celltype_labels).sum().item()) / celltype_labels.size(0)\n",
    "            \n",
    "        model.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings(\"always\")\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(),\n",
    "                1.0,\n",
    "                error_if_nonfinite=False if scaler.is_enabled() else True,\n",
    "            )\n",
    "            if len(w) > 0:\n",
    "                logger.warning(\n",
    "                    f\"Found infinite gradient. This may be caused by the gradient \"\n",
    "                    f\"scaler. The current scale is {scaler.get_scale()}. This warning \"\n",
    "                    \"can be ignored if no longer occurs after autoscaling of the scaler.\"\n",
    "                )\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_mse += loss_mse.item() if MLM else 0.0\n",
    "        total_cls += loss_cls.item() if CLS else 0.0\n",
    "        total_zero_log_prob += loss_zero_log_prob.item() if explicit_zero_prob else 0.0\n",
    "        total_error += error_rate\n",
    "\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            cur_mse = total_mse / log_interval\n",
    "            cur_cls = total_cls / log_interval if CLS else 0.0\n",
    "            cur_zero_log_prob = total_zero_log_prob / log_interval if explicit_zero_prob else 0.0\n",
    "            cur_error = total_error / log_interval\n",
    "\n",
    "            logger.info(\n",
    "                f\"| epoch {epoch:3d} | {batch:3d}/{num_batches:3d} batches | \"\n",
    "                f\"lr {lr:05.4f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | \"\n",
    "                + (f\"mse {cur_mse:5.2f} | mre {cur_error:5.2f} |\" if MLM else \"\")\n",
    "                + (f\"cls {cur_cls:5.2f} | \" if CLS else \"\")\n",
    "                + (f\"err {cur_error:5.2f} | \" if CLS else \"\")\n",
    "                + (f\"nzlp {cur_zero_log_prob:5.2f} |\" if explicit_zero_prob else \"\")\n",
    "            )\n",
    "\n",
    "            total_loss = 0\n",
    "            total_mse = 0\n",
    "            total_cls = 0\n",
    "            total_zero_log_prob = 0\n",
    "            total_error = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "'''\n",
    "def eval_no_dropout(model):\n",
    "    model.train()\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.eval()\n",
    "    return model\n",
    "'''\n",
    "\n",
    "\n",
    "#@torch.no_grad()\n",
    "def evaluateog(model: nn.Module, loader: DataLoader,return_raw: bool = False) -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_error = 0.0\n",
    "    num_batches = len(loader)\n",
    "    predictions = []\n",
    "    for batch_data in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        input_gene_ids = batch_data[\"gene_ids\"].to(device, non_blocking=True)\n",
    "        input_values   = batch_data[\"values\"].to(device, non_blocking=True)\n",
    "        target_values  = batch_data[\"target\"].to(device, non_blocking=True)\n",
    "        celltype_labels = batch_data[\"celltype_labels\"].to(device, non_blocking=True)\n",
    "        src_key_padding_mask = input_gene_ids.eq(vocab[pad_token])\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            output_dict = model(\n",
    "                input_gene_ids,\n",
    "                input_values,\n",
    "                src_key_padding_mask=src_key_padding_mask,\n",
    "                batch_labels=None,\n",
    "                CLS=CLS, CCE=CCE, MVC=MVC, ECS=ECS, do_sample=False,\n",
    "            )\n",
    "            output_values = output_dict[\"cls_output\"]\n",
    "            loss = criterion_cls(output_values, celltype_labels)\n",
    "            if CLS:\n",
    "                loss_cls = criterion_cls(output_dict[\"cls_output\"], celltype_labels)\n",
    "                loss += loss_cls\n",
    "                error = 1 - ((output_dict[\"cls_output\"].argmax(1) == celltype_labels).sum().item()) / celltype_labels.size(0)\n",
    "        preds = output_values.argmax(1).cpu().numpy()\n",
    "        predictions.append(preds)\n",
    "        total_loss += loss.item()\n",
    "        total_error += error\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_error = total_error / num_batches\n",
    "    if return_raw:\n",
    "        return predictions\n",
    "    return avg_loss, avg_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "843e407c-7cae-48de-a8cb-d5a24cd0878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   1, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   1 | 100/155 batches | lr 0.0001 | ms/batch 230.89 | loss  1.37 | cls  1.37 | err  0.49 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   1 | time: 39.12s | valid loss/mse 0.9692 | err 0.1625\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Best model with score 0.969169910\n",
      "random masking at epoch   2, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   2 | 100/155 batches | lr 0.0001 | ms/batch 223.34 | loss  0.38 | cls  0.38 | err  0.12 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   2 | time: 38.50s | valid loss/mse 0.4070 | err 0.0461\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Best model with score 0.406984711\n",
      "random masking at epoch   3, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   3 | 100/155 batches | lr 0.0001 | ms/batch 224.55 | loss  0.21 | cls  0.21 | err  0.06 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   3 | time: 39.00s | valid loss/mse 0.4028 | err 0.0444\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Best model with score 0.402807827\n",
      "random masking at epoch   4, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   4 | 100/155 batches | lr 0.0001 | ms/batch 225.19 | loss  0.17 | cls  0.17 | err  0.05 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   4 | time: 38.94s | valid loss/mse 0.4505 | err 0.0496\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   5, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   5 | 100/155 batches | lr 0.0001 | ms/batch 226.65 | loss  0.15 | cls  0.15 | err  0.04 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   5 | time: 39.02s | valid loss/mse 0.2759 | err 0.0295\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Best model with score 0.275863568\n",
      "random masking at epoch   6, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:21<00:11,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   6 | 100/155 batches | lr 0.0001 | ms/batch 221.59 | loss  0.14 | cls  0.14 | err  0.03 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   6 | time: 38.56s | valid loss/mse 0.3184 | err 0.0322\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   7, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   7 | 100/155 batches | lr 0.0001 | ms/batch 226.20 | loss  0.13 | cls  0.13 | err  0.03 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   7 | time: 38.95s | valid loss/mse 0.2972 | err 0.0357\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   8, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:22<00:11,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   8 | 100/155 batches | lr 0.0001 | ms/batch 222.39 | loss  0.12 | cls  0.12 | err  0.03 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   8 | time: 38.57s | valid loss/mse 0.2828 | err 0.0305\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   9, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 100/155 [00:21<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch   9 | 100/155 batches | lr 0.0001 | ms/batch 221.22 | loss  0.10 | cls  0.10 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   9 | time: 38.40s | valid loss/mse 0.3034 | err 0.0402\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  10, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  10 | 100/155 batches | lr 0.0001 | ms/batch 224.36 | loss  0.09 | cls  0.09 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  10 | time: 38.74s | valid loss/mse 0.2943 | err 0.0305\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  11, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  11 | 100/155 batches | lr 0.0001 | ms/batch 225.00 | loss  0.09 | cls  0.09 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  11 | time: 38.87s | valid loss/mse 0.2164 | err 0.0288\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Best model with score 0.216374342\n",
      "random masking at epoch  12, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  12 | 100/155 batches | lr 0.0001 | ms/batch 225.18 | loss  0.09 | cls  0.09 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  12 | time: 38.89s | valid loss/mse 0.2799 | err 0.0260\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  13, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  13 | 100/155 batches | lr 0.0001 | ms/batch 224.78 | loss  0.10 | cls  0.10 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  13 | time: 38.79s | valid loss/mse 0.2913 | err 0.0305\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  14, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  14 | 100/155 batches | lr 0.0001 | ms/batch 224.56 | loss  0.07 | cls  0.07 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  14 | time: 38.79s | valid loss/mse 0.2802 | err 0.0243\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  15, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15:  65%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 100/155 [00:22<00:11,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - | epoch  15 | 100/155 batches | lr 0.0000 | ms/batch 224.94 | loss  0.07 | cls  0.07 | err  0.02 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch  15 | time: 38.86s | valid loss/mse 0.2781 | err 0.0288\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch  16, ratio of masked values in train:  0.1471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16:  22%|████████████████████████████████▏                                                                                                                  | 34/155 [00:08<00:25,  4.72it/s]Exception in thread Thread-36 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 495, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 24\u001b[0m\n\u001b[1;32m     15\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m prepare_dataloader(\n\u001b[1;32m     16\u001b[0m     valid_data_pt,\n\u001b[1;32m     17\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdo_train:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mchatgpt_train_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m val_loss, val_err \u001b[38;5;241m=\u001b[39m evaluateog(\n\u001b[1;32m     29\u001b[0m     model,\n\u001b[1;32m     30\u001b[0m     loader\u001b[38;5;241m=\u001b[39mvalid_loader,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start_time\n",
      "Cell \u001b[0;32mIn[118], line 228\u001b[0m, in \u001b[0;36mchatgpt_train_main\u001b[0;34m(model, loader, epoch)\u001b[0m\n\u001b[1;32m    226\u001b[0m metrics_to_log \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m--> 228\u001b[0m     output_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_gene_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCLS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCCE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMVC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMVC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mECS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample_in_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m masked_positions \u001b[38;5;241m=\u001b[39m input_values\u001b[38;5;241m.\u001b[39meq(mask_value)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MLM:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scgpt/model/model.py:345\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, values, src_key_padding_mask, batch_labels, CLS, CCE, MVC, ECS, do_sample)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    316\u001b[0m     src: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     do_sample: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m        src (:obj:`Tensor`): token ids, shape [batch_size, seq_len]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m        dict of output Tensors.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m     transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_batch_labels:\n\u001b[1;32m    349\u001b[0m         batch_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encoder(batch_labels)  \u001b[38;5;66;03m# (batch, embsize)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scgpt/model/model.py:194\u001b[0m, in \u001b[0;36mTransformerModel._encode\u001b[0;34m(self, src, values, src_key_padding_mask, batch_labels)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     total_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(total_embs\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 194\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:750\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal))\n\u001b[0;32m--> 750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:765\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 765\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_avg_bio = 0.0\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_data_pt, valid_data_pt = prepare_data()\n",
    "    train_loader = prepare_dataloader(\n",
    "        train_data_pt,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    valid_loader = prepare_dataloader(\n",
    "        valid_data_pt,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    if config.do_train:\n",
    "        chatgpt_train_main(\n",
    "            model,\n",
    "            loader=train_loader,epoch=epoch\n",
    "        )\n",
    "    val_loss, val_err = evaluateog(\n",
    "        model,\n",
    "        loader=valid_loader,\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(\n",
    "        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "        f\"valid loss/mse {val_loss:5.4f} | err {val_err:5.4f}\"\n",
    "    )\n",
    "    logger.info(\"-\" * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_state, \"final_classification_melenoma.pt\")\n",
    "        best_model_epoch = epoch\n",
    "        logger.info(f\"Best model with score {best_val_loss:5.9f}\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4f68f46-385e-48a2-ad14-918d28e32d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testf(model: nn.Module, adata: DataLoader) -> float:\n",
    "    adata.obs[\"class id\"] = adata.obs[\"cell.types\"].map(type2id_train)\n",
    "    input_layer_key = \"X_binned\"\n",
    "    all_counts = (\n",
    "        adata.layers[input_layer_key].toarray()\n",
    "        if issparse(adata.layers[input_layer_key])\n",
    "        else adata.layers[input_layer_key]\n",
    "    )\n",
    "\n",
    "    celltypes_labels = adata.obs[\"class id\"].tolist()  # make sure count from 0\n",
    "    celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "    tokenized_test = tokenize_and_pad_batchy(\n",
    "        all_counts,\n",
    "        gene_ids,\n",
    "        max_len=max_seq_len,\n",
    "        vocab=vocab,\n",
    "        pad_token=pad_token,\n",
    "        pad_value=pad_value,\n",
    "        append_cls=True,  # append <cls> token at the beginning\n",
    "        include_zero_gene=include_zero_gene,\n",
    "    )\n",
    "\n",
    "    input_values_test = random_mask_value(\n",
    "        tokenized_test[\"values\"],\n",
    "        mask_ratio=mask_ratio,\n",
    "        mask_value=mask_value,\n",
    "        pad_value=pad_value,\n",
    "    )\n",
    "\n",
    "    test_data_pt = {\n",
    "        \"gene_ids\": tokenized_test[\"genes\"],\n",
    "        \"values\": input_values_test,\n",
    "        \"target\": tokenized_test[\"values\"],\n",
    "        \"celltype_labels\": torch.from_numpy(celltypes_labels).long(),\n",
    "    }\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=SeqDataset(test_data_pt),\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=min(len(os.sched_getaffinity(0)), eval_batch_size // 2),\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    predictions = evaluateog(\n",
    "        model,\n",
    "        loader=test_loader,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    predictions = np.concatenate(predictions)\n",
    "# compute accuracy, precision, recall, f1\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "    accuracy = accuracy_score(celltypes_labels, predictions)\n",
    "    precision = precision_score(celltypes_labels, predictions, average=\"macro\")\n",
    "    recall = recall_score(celltypes_labels, predictions, average=\"macro\")\n",
    "    macro_f1 = f1_score(celltypes_labels, predictions, average=\"macro\")\n",
    "\n",
    "    logger.info(\n",
    "        f\"Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, \"\n",
    "        f\"Macro F1: {macro_f1:.3f}\"\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        \"test/accuracy\": accuracy,\n",
    "        \"test/precision\": precision,\n",
    "        \"test/recall\": recall,\n",
    "        \"test/macro_f1\": macro_f1,\n",
    "    }\n",
    "\n",
    "    return predictions,celltypes_labels,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "216d2b29-7cb9-4a53-b9f5-85de3aad2e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('final_classification_melenoma.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5fd3be0b-19bb-4609-b49a-00d28b819f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Accuracy: 0.964, Precision: 0.914, Recall: 0.904, Macro F1: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictions = testf(model,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd05d2c0-31c9-4730-bf99-c159bb58f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,celltypes_labels,results = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "054ee57d-4fdd-4fb0-9a64-21efe1266d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 4, ..., 5, 1, 7])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celltypes_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "416e9c07-b17b-49fa-a744-4a363874114a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test/accuracy': 0.9643895348837209,\n",
       " 'test/precision': 0.914420568544977,\n",
       " 'test/recall': 0.9044512056332985,\n",
       " 'test/macro_f1': 0.9090877780523887}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d43844f-427c-44d7-bd8b-3a24f016ae49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Could not find key cell.type in .var_names or .obs.columns.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m palette_ \u001b[38;5;241m=\u001b[39m {c: palette_[i] \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(celltypes)}\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plt\u001b[38;5;241m.\u001b[39mrc_context({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.dpi\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m300\u001b[39m)}):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mumap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcell.type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpalette_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(save_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m     16\u001b[0m save_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: predictions,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: celltypes_labels,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: results,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_maps\u001b[39m\u001b[38;5;124m\"\u001b[39m: id2type_train\n\u001b[1;32m     21\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:686\u001b[0m, in \u001b[0;36mumap\u001b[0;34m(adata, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;129m@_wraps_plot_scatter\u001b[39m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;129m@_doc_params\u001b[39m(\n\u001b[1;32m    629\u001b[0m     adata_color_etc\u001b[38;5;241m=\u001b[39mdoc_adata_color_etc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    633\u001b[0m )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mumap\u001b[39m(adata: AnnData, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Figure \u001b[38;5;241m|\u001b[39m Axes \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[Axes] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scatter plot in UMAP basis.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m \n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:279\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(adata, basis, color, mask_obs, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, marker, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, (value_to_plot, dims) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(color, dimensions, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m    278\u001b[0m     kwargs_scatter \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# is potentially mutated for each plot\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     color_source_vector \u001b[38;5;241m=\u001b[39m \u001b[43m_get_color_source_vector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_to_plot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_obs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgene_symbols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgene_symbols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m     color_vector, color_type \u001b[38;5;241m=\u001b[39m _color_vector(\n\u001b[1;32m    289\u001b[0m         adata,\n\u001b[1;32m    290\u001b[0m         value_to_plot,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m         na_color\u001b[38;5;241m=\u001b[39mna_color,\n\u001b[1;32m    294\u001b[0m     )\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# Order points\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scanpy/plotting/_tools/scatterplots.py:1200\u001b[0m, in \u001b[0;36m_get_color_source_vector\u001b[0;34m(adata, value_to_plot, mask_obs, use_raw, gene_symbols, layer, groups)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     values \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mobs_vector(value_to_plot)\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1200\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_to_plot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/anndata/_core/anndata.py:1297\u001b[0m, in \u001b[0;36mAnnData.obs_vector\u001b[0;34m(self, k, layer)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1292\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn a future version of AnnData, access to `.X` by passing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `layer=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` will be removed. Instead pass `layer=None`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1295\u001b[0m         )\n\u001b[1;32m   1296\u001b[0m         layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/anndata/_core/index.py:245\u001b[0m, in \u001b[0;36mget_vector\u001b[0;34m(adata, k, coldim, idxdim, layer)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (in_col \u001b[38;5;241m+\u001b[39m in_idx) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in .\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midxdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_names or .\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoldim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(msg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m in_col:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(adata, coldim)[k]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Could not find key cell.type in .var_names or .obs.columns.'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4122x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc.pp.neighbors(test, n_neighbors=15, use_rep='X')\n",
    "sc.tl.umap(test)\n",
    "test.obs[\"predictions\"] = [id2type_train[p] for p in predictions]\n",
    "# plot\n",
    "palette_ = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"] \n",
    "palette_ = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"] + plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"] + plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "palette_ = {c: palette_[i] for i, c in enumerate(celltypes)}\n",
    "\n",
    "with plt.rc_context({\"figure.figsize\": (6, 4), \"figure.dpi\": (300)}):\n",
    "    sc.pl.umap(\n",
    "        test,\n",
    "        color=[\"cell.type\", \"predictions\"],\n",
    "        palette=palette_,\n",
    "        show=False,\n",
    "    )\n",
    "    plt.savefig(save_dir / \"results.png\", dpi=300)\n",
    "\n",
    "save_dict = {\n",
    "    \"predictions\": predictions,\n",
    "    \"labels\": celltypes_labels,\n",
    "    \"results\": results,\n",
    "    \"id_maps\": id2type_train\n",
    "}\n",
    "with open(save_dir / \"results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(save_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d1510-eb7e-48ff-aade-e4b104e81e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
